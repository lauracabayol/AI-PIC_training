{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "061f6017-5f4d-4782-88ee-40be62707515",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "289782b9-0d1f-40fa-8a1b-abe0871ff0fd",
   "metadata": {},
   "source": [
    "# 01. TENSORS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6542d693-a04b-4fc6-98d6-a1de1771d4ca",
   "metadata": {},
   "source": [
    "## TABLE OF CONTENTS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81c9c5c6-5b61-4ff3-9449-e02eacf73502",
   "metadata": {},
   "source": [
    "#### 1. What are Tensors?\n",
    "#### 2. Creating Tensors\n",
    "#### 3. Basic Operations\n",
    "#### 4. Reshaping Tensors\n",
    "#### 5. Broadcasting Tensors\n",
    "#### 6. Indexing and Slicing\n",
    "#### 7. Moving Tensors to GPU (Optional)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2826fc2-3ce3-4f94-bdbb-6818c6554d5d",
   "metadata": {},
   "source": [
    "## 1. What are Tensors?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c4d8bf2-ff07-471c-8258-197e7677512e",
   "metadata": {},
   "source": [
    "Tensors are multi-dimensional arrays that can be used to represent numerical data. In PyTorch, tensors are the primary data structure for representing data that will be fed into neural networks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7294d595-0ec2-492c-abdb-c41884b8ad6f",
   "metadata": {},
   "source": [
    "## 2. Creating Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f9fec4e1-37a2-465c-8aba-966347a00c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a 1D tensor\n",
    "x = torch.Tensor([1, 2, 3, 4, 5])\n",
    "# Creating a 2D tensor\n",
    "y = torch.Tensor([[1, 2, 3], [4, 5, 6]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f06e5cc3-b995-446a-a684-ef8ef768d53d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1., 2., 3., 4., 5.]),\n",
       " tensor([[1., 2., 3.],\n",
       "         [4., 5., 6.]]))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1d02cd73-dd70-4448-ad3a-72c7a6a3f987",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a tensor of all zeros\n",
    "z = torch.zeros(2, 3)\n",
    "\n",
    "# Creating a tensor of all ones\n",
    "w = torch.ones(2, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f8961b39-35ab-4ac7-9460-160b1f2fa5f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0., 0., 0.],\n",
       "         [0., 0., 0.]]),\n",
       " tensor([[1., 1., 1.],\n",
       "         [1., 1., 1.]]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z,w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "95b9699a-40a8-441a-b891-58206ad8052e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a tensor with random values\n",
    "#from a normal distribution\n",
    "rn = torch.randn(1000)\n",
    "#from a uniform distribution\n",
    "ru = torch.rand(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "748c17fe-a3de-404a-b1b3-7054a926e70f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([116.,  83.,  97., 103.,  85., 101.,  97., 116.,  90., 112.]),\n",
       " array([0.00102872, 0.1008215 , 0.20061429, 0.30040708, 0.40019986,\n",
       "        0.49999264, 0.59978545, 0.6995782 , 0.799371  , 0.8991638 ,\n",
       "        0.99895656], dtype=float32),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAigAAAGdCAYAAAA44ojeAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAaGElEQVR4nO3df2yW9b3/8dc9kIKsdBakpbFAs7HEHIjJcGEjbsLUOjL1MLfpjomHJezETSVp0DmZyVnPcg5snjM1kY1tJ4s4N6ZLNtQEk2OXOZwhZko0TnNmdEKAQYM/WAuM0zq8zx/77v6eCiqF1vtTeDySK/G+rk/b930F4ZnrvnvdlWq1Wg0AQEHeU+8BAADeTKAAAMURKABAcQQKAFAcgQIAFEegAADFESgAQHEECgBQnPH1HuB4vPHGG9m9e3caGxtTqVTqPQ4AcAyq1Wr279+ftra2vOc9b3+NZEwGyu7du9Pe3l7vMQCA47Bz586cddZZb7tmTAZKY2Njkr8+wSlTptR5GgDgWPT396e9vb327/jbGZOB8reXdaZMmSJQAGCMOZa3Z3iTLABQHIECABRHoAAAxREoAEBxBAoAUByBAgAUR6AAAMURKABAcQQKAFAcgQIAFEegAADFESgAQHEECgBQHIECABRnfL0HAHiz2TdvqvcIw7b9m5+q9whwUnEFBQAojkABAIojUACA4ggUAKA4AgUAKI5AAQCKI1AAgOIIFACgOAIFACiOQAEAiiNQAIDiCBQAoDgCBQAojkABAIojUACA4ggUAKA4AgUAKI5AAQCKI1AAgOIIFACgOAIFACiOQAEAiiNQAIDiCBQAoDgCBQAojkABAIojUACA4ggUAKA4AgUAKI5AAQCKI1AAgOIIFACgOAIFACiOQAEAiiNQAIDiCBQAoDgCBQAojkABAIojUACA4ggUAKA4AgUAKI5AAQCKI1AAgOIIFACgOAIFACiOQAEAiiNQAIDiCBQAoDgCBQAojkABAIojUACA4gwrUNasWZMPf/jDaWxszPTp07N06dI8//zzQ9ZUq9V0d3enra0tkyZNyqJFi/Lcc88NWTMwMJAVK1Zk2rRpmTx5ci677LLs2rXrxJ8NAHBSGFagbN68Odddd10ef/zx9PT05C9/+Us6Oztz8ODB2ppbb701t912W9auXZsnnngira2tueiii7J///7amq6urmzcuDH33ntvHnvssRw4cCCXXHJJDh8+PHLPDAAYsyrVarV6vF/88ssvZ/r06dm8eXM+/vGPp1qtpq2tLV1dXfnqV7+a5K9XS1paWvKtb30r11xzTfr6+nLmmWfmnnvuyZVXXpkk2b17d9rb2/PQQw/l4osvfsef29/fn6ampvT19WXKlCnHOz5QqNk3b6r3CMO2/ZufqvcIULzh/Pt9Qu9B6evrS5I0NzcnSbZt25be3t50dnbW1jQ0NOT888/Pli1bkiRbt27N66+/PmRNW1tb5s6dW1vzZgMDA+nv7x+yAQAnr+MOlGq1mpUrV+a8887L3LlzkyS9vb1JkpaWliFrW1paasd6e3szYcKEnHHGGW+55s3WrFmTpqam2tbe3n68YwMAY8BxB8r111+fZ555Jj/96U+POFapVIY8rlarR+x7s7dbs2rVqvT19dW2nTt3Hu/YAMAYcFyBsmLFijz44IN55JFHctZZZ9X2t7a2JskRV0L27t1bu6rS2tqawcHB7Nu37y3XvFlDQ0OmTJkyZAMATl7DCpRqtZrrr78+v/jFL/KrX/0qHR0dQ453dHSktbU1PT09tX2Dg4PZvHlzFi5cmCSZP39+TjvttCFr9uzZk2effba2BgA4tY0fzuLrrrsuGzZsyAMPPJDGxsbalZKmpqZMmjQplUolXV1dWb16debMmZM5c+Zk9erVOf3003PVVVfV1i5fvjw33HBDpk6dmubm5tx4442ZN29eLrzwwpF/hgDAmDOsQFm3bl2SZNGiRUP233XXXfnCF76QJLnpppty6NChXHvttdm3b18WLFiQhx9+OI2NjbX1t99+e8aPH58rrrgihw4dygUXXJD169dn3LhxJ/ZsAICTwgndB6Ve3AcFTm7ugwInp3ftPigAAKNBoAAAxREoAEBxBAoAUJxh/RYPAEc3Ft/Ym3hzL+VyBQUAKI5AAQCKI1AAgOIIFACgOAIFACiOQAEAiiNQAIDiCBQAoDgCBQAojkABAIojUACA4ggUAKA4AgUAKI5AAQCKI1AAgOIIFACgOAIFACjO+HoPAIyu2TdvqvcIAMPmCgoAUByBAgAUR6AAAMURKABAcQQKAFAcgQIAFEegAADFESgAQHEECgBQHIECABRHoAAAxREoAEBxBAoAUByBAgAUR6AAAMURKABAcQQKAFAcgQIAFEegAADFESgAQHEECgBQHIECABRHoAAAxREoAEBxBAoAUByBAgAUR6AAAMURKABAcQQKAFAcgQIAFEegAADFESgAQHEECgBQHIECABRHoAAAxREoAEBxBAoAUByBAgAUR6AAAMURKABAcYYdKI8++mguvfTStLW1pVKp5P777x9y/Atf+EIqlcqQ7SMf+ciQNQMDA1mxYkWmTZuWyZMn57LLLsuuXbtO6IkAACePYQfKwYMHc84552Tt2rVvueaTn/xk9uzZU9seeuihIce7urqycePG3HvvvXnsscdy4MCBXHLJJTl8+PDwnwEAcNIZP9wvWLJkSZYsWfK2axoaGtLa2nrUY319ffnhD3+Ye+65JxdeeGGS5Mc//nHa29vzy1/+MhdffPFwRwIATjKj8h6UX//615k+fXo++MEP5p/+6Z+yd+/e2rGtW7fm9ddfT2dnZ21fW1tb5s6dmy1bthz1+w0MDKS/v3/IBgCcvEY8UJYsWZKf/OQn+dWvfpVvf/vbeeKJJ/KJT3wiAwMDSZLe3t5MmDAhZ5xxxpCva2lpSW9v71G/55o1a9LU1FTb2tvbR3psAKAgw36J551ceeWVtf+eO3duzj333MyaNSubNm3K5Zdf/pZfV61WU6lUjnps1apVWblyZe1xf3+/SAGAk9io/5rxjBkzMmvWrLzwwgtJktbW1gwODmbfvn1D1u3duzctLS1H/R4NDQ2ZMmXKkA0AOHmNeqC8+uqr2blzZ2bMmJEkmT9/fk477bT09PTU1uzZsyfPPvtsFi5cONrjAABjwLBf4jlw4EBefPHF2uNt27bl6aefTnNzc5qbm9Pd3Z3PfOYzmTFjRrZv356vfe1rmTZtWj796U8nSZqamrJ8+fLccMMNmTp1apqbm3PjjTdm3rx5td/qAQBObcMOlCeffDKLFy+uPf7be0OWLVuWdevW5Xe/+11+9KMf5U9/+lNmzJiRxYsX57777ktjY2Pta26//faMHz8+V1xxRQ4dOpQLLrgg69evz7hx40bgKQEAY12lWq1W6z3EcPX396epqSl9fX3ejwLvYPbNm+o9AgXb/s1P1XsETiHD+ffbZ/EAAMURKABAcQQKAFAcgQIAFEegAADFESgAQHEECgBQHIECABRHoAAAxREoAEBxBAoAUByBAgAUR6AAAMURKABAcQQKAFAcgQIAFEegAADFESgAQHEECgBQHIECABRHoAAAxREoAEBxBAoAUByBAgAUR6AAAMURKABAcQQKAFAcgQIAFEegAADFESgAQHEECgBQHIECABRnfL0HgLFk9s2b6j0CwCnBFRQAoDgCBQAojkABAIojUACA4ggUAKA4AgUAKI5AAQCKI1AAgOIIFACgOAIFACiOQAEAiuOzeIBTxvaJV73t8dn/s+FdmmR0vNPzS8b+c+TU4QoKAFAcgQIAFEegAADFESgAQHEECgBQHL/FA8D/1930Dsf73p05OOW5ggIAFEegAADFESgAQHG8BwXgFDb75k1DHm+fOLz19bD9m5+q9wi8C1xBAQCKI1AAgOIIFACgOAIFACiOQAEAiiNQAIDiCBQAoDgCBQAozrAD5dFHH82ll16atra2VCqV3H///UOOV6vVdHd3p62tLZMmTcqiRYvy3HPPDVkzMDCQFStWZNq0aZk8eXIuu+yy7Nq164SeCEC9bZ941dtuwLEbdqAcPHgw55xzTtauXXvU47feemtuu+22rF27Nk888URaW1tz0UUXZf/+/bU1XV1d2bhxY+6999489thjOXDgQC655JIcPnz4+J8JAHDSGPat7pcsWZIlS5Yc9Vi1Ws0dd9yRW265JZdffnmS5O67705LS0s2bNiQa665Jn19ffnhD3+Ye+65JxdeeGGS5Mc//nHa29vzy1/+MhdffPEJPB0A4GQwop/Fs23btvT29qazs7O2r6GhIeeff362bNmSa665Jlu3bs3rr78+ZE1bW1vmzp2bLVu2HDVQBgYGMjAwUHvc398/kmMDFOGdXgaa/T8b3qVJoP5G9E2yvb29SZKWlpYh+1taWmrHent7M2HChJxxxhlvuebN1qxZk6amptrW3t4+kmMDAIUZld/iqVQqQx5Xq9Uj9r3Z261ZtWpV+vr6atvOnTtHbFYAoDwjGiitra1JcsSVkL1799auqrS2tmZwcDD79u17yzVv1tDQkClTpgzZAICT14gGSkdHR1pbW9PT01PbNzg4mM2bN2fhwoVJkvnz5+e0004bsmbPnj159tlna2sAgFPbsN8ke+DAgbz44ou1x9u2bcvTTz+d5ubmzJw5M11dXVm9enXmzJmTOXPmZPXq1Tn99NNz1VV/ffNXU1NTli9fnhtuuCFTp05Nc3NzbrzxxsybN6/2Wz0AwKlt2IHy5JNPZvHixbXHK1euTJIsW7Ys69evz0033ZRDhw7l2muvzb59+7JgwYI8/PDDaWxsrH3N7bffnvHjx+eKK67IoUOHcsEFF2T9+vUZN27cCDwlgNFR75ut1fvnw7tp2IGyaNGiVKvVtzxeqVTS3d2d7u7ut1wzceLE3HnnnbnzzjuH++MBgFOAz+IBAIojUACA4ggUAKA4AgUAKI5AAQCKI1AAgOIIFACgOAIFACjOsG/UBsDY5W60jBWuoAAAxREoAEBxBAoAUByBAgAUR6AAAMURKABAcQQKAFAc90EBeJe4BwkcO1dQAIDiCBQAoDhe4gH4f7wEA+VwBQUAKI5AAQCKI1AAgOIIFACgOAIFACiOQAEAiiNQAIDiCBQAoDgCBQAojkABAIojUACA4ggUAKA4AgUAKI5AAQCKI1AAgOIIFACgOAIFACiOQAEAijO+3gNw6pp986Z6jwBAoVxBAQCKI1AAgOIIFACgOAIFACiOQAEAiiNQAIDiCBQAoDgCBQAojkABAIojUACA4ggUAKA4AgUAKI5AAQCKI1AAgOIIFACgOAIFACiOQAEAiiNQAIDiCBQAoDgCBQAojkABAIojUACA4ggUAKA4AgUAKM6IB0p3d3cqlcqQrbW1tXa8Wq2mu7s7bW1tmTRpUhYtWpTnnntupMcAAMawUbmC8nd/93fZs2dPbfvd735XO3brrbfmtttuy9q1a/PEE0+ktbU1F110Ufbv3z8aowAAY9CoBMr48ePT2tpa284888wkf716cscdd+SWW27J5Zdfnrlz5+buu+/On//852zYsGE0RgEAxqBRCZQXXnghbW1t6ejoyOc///m89NJLSZJt27alt7c3nZ2dtbUNDQ05//zzs2XLlrf8fgMDA+nv7x+yAQAnrxEPlAULFuRHP/pR/uu//iv/+Z//md7e3ixcuDCvvvpqent7kyQtLS1DvqalpaV27GjWrFmTpqam2tbe3j7SYwMABRnxQFmyZEk+85nPZN68ebnwwguzadOmJMndd99dW1OpVIZ8TbVaPWLf/7Vq1ar09fXVtp07d4702ABAQcaP9g+YPHly5s2blxdeeCFLly5NkvT29mbGjBm1NXv37j3iqsr/1dDQkIaGhtEeFYAxYPbNm+o9wrBt/+an6j3CmDPq90EZGBjIf//3f2fGjBnp6OhIa2trenp6ascHBwezefPmLFy4cLRHAQDGiBG/gnLjjTfm0ksvzcyZM7N3797867/+a/r7+7Ns2bJUKpV0dXVl9erVmTNnTubMmZPVq1fn9NNPz1VXXTXSowAAY9SIB8quXbvyD//wD3nllVdy5pln5iMf+Ugef/zxzJo1K0ly00035dChQ7n22muzb9++LFiwIA8//HAaGxtHehQAYIwa8UC599573/Z4pVJJd3d3uru7R/pHAwAnCZ/FAwAUR6AAAMURKABAcQQKAFAcgQIAFEegAADFESgAQHEECgBQHIECABRHoAAAxREoAEBxBAoAUByBAgAUR6AAAMURKABAcQQKAFAcgQIAFEegAADFESgAQHEECgBQHIECABRHoAAAxREoAEBxBAoAUByBAgAUR6AAAMURKABAcQQKAFAcgQIAFEegAADFESgAQHEECgBQHIECABRHoAAAxREoAEBxBAoAUByBAgAUR6AAAMURKABAccbXewAAONnNvnlTvUcYtu3f/FRdf74rKABAcQQKAFAcgQIAFEegAADFESgAQHEECgBQHIECABRHoAAAxREoAEBxBAoAUBy3uj9JjMXbKAPAW3EFBQAojkABAIojUACA4ggUAKA4AgUAKI5AAQCKI1AAgOIIFACgOAIFACiOO8kehbuyAkB9uYICABRHoAAAxalroHz3u99NR0dHJk6cmPnz5+c3v/lNPccBAApRt0C577770tXVlVtuuSVPPfVUPvaxj2XJkiXZsWNHvUYCAApRt0C57bbbsnz58nzxi1/M2WefnTvuuCPt7e1Zt25dvUYCAApRl9/iGRwczNatW3PzzTcP2d/Z2ZktW7YcsX5gYCADAwO1x319fUmS/v7+UZnvjYE/j8r3Beqrv1Kt9whjnr8fTx2j8W/s375ntfrO/y/WJVBeeeWVHD58OC0tLUP2t7S0pLe394j1a9asyb/8y78csb+9vX3UZgROPk31HuCkcEW9B+Bd0nTH6H3v/fv3p6np7f+PrOt9UCqVypDH1Wr1iH1JsmrVqqxcubL2+I033shrr72WqVOnHnX9SOrv7097e3t27tyZKVOmjOrPOlk5hyfOOTxxzuGJcw5P3Kl+DqvVavbv35+2trZ3XFuXQJk2bVrGjRt3xNWSvXv3HnFVJUkaGhrS0NAwZN/73ve+0RzxCFOmTDkl/zCNJOfwxDmHJ845PHHO4Yk7lc/hO105+Zu6vEl2woQJmT9/fnp6eobs7+npycKFC+sxEgBQkLq9xLNy5cpcffXVOffcc/PRj340P/jBD7Jjx4586UtfqtdIAEAh6hYoV155ZV599dV84xvfyJ49ezJ37tw89NBDmTVrVr1GOqqGhoZ8/etfP+IlJo6dc3jinMMT5xyeOOfwxDmHx65SPZbf9QEAeBf5LB4AoDgCBQAojkABAIojUACA4giUYbjssssyc+bMTJw4MTNmzMjVV1+d3bt313usMWP79u1Zvnx5Ojo6MmnSpLz//e/P17/+9QwODtZ7tDHl3/7t37Jw4cKcfvrp7/oNC8eq7373u+no6MjEiRMzf/78/OY3v6n3SGPKo48+mksvvTRtbW2pVCq5//776z3SmLJmzZp8+MMfTmNjY6ZPn56lS5fm+eefr/dYxRMow7B48eL87Gc/y/PPP5+f//zn+cMf/pDPfvaz9R5rzPj973+fN954I9///vfz3HPP5fbbb8/3vve9fO1rX6v3aGPK4OBgPve5z+XLX/5yvUcZE+677750dXXllltuyVNPPZWPfexjWbJkSXbs2FHv0caMgwcP5pxzzsnatWvrPcqYtHnz5lx33XV5/PHH09PTk7/85S/p7OzMwYMH6z1a0fya8Ql48MEHs3Tp0gwMDOS0006r9zhj0r//+79n3bp1eemll+o9ypizfv36dHV15U9/+lO9RynaggUL8qEPfSjr1q2r7Tv77LOzdOnSrFmzpo6TjU2VSiUbN27M0qVL6z3KmPXyyy9n+vTp2bx5cz7+8Y/Xe5xiuYJynF577bX85Cc/ycKFC8XJCejr60tzc3O9x+AkNTg4mK1bt6azs3PI/s7OzmzZsqVOU3Gq6+vrSxJ/970DgTJMX/3qVzN58uRMnTo1O3bsyAMPPFDvkcasP/zhD7nzzjt9vAGj5pVXXsnhw4eP+BDSlpaWIz6sFN4N1Wo1K1euzHnnnZe5c+fWe5yinfKB0t3dnUql8rbbk08+WVv/la98JU899VQefvjhjBs3Lv/4j/+YU/1VsuGewyTZvXt3PvnJT+Zzn/tcvvjFL9Zp8nIczznk2FUqlSGPq9XqEfvg3XD99dfnmWeeyU9/+tN6j1K8un0WTymuv/76fP7zn3/bNbNnz67997Rp0zJt2rR88IMfzNlnn5329vY8/vjj+ehHPzrKk5ZruOdw9+7dWbx4ce1DIhn+OeTYTJs2LePGjTviasnevXuPuKoCo23FihV58MEH8+ijj+ass86q9zjFO+UD5W/BcTz+duVkYGBgJEcac4ZzDv/4xz9m8eLFmT9/fu6666685z2n/EW8JCf255C3NmHChMyfPz89PT359Kc/Xdvf09OTv//7v6/jZJxKqtVqVqxYkY0bN+bXv/51Ojo66j3SmHDKB8qx+u1vf5vf/va3Oe+883LGGWfkpZdeyj//8z/n/e9//yl99WQ4du/enUWLFmXmzJn5j//4j7z88su1Y62trXWcbGzZsWNHXnvttezYsSOHDx/O008/nST5wAc+kPe+9731Ha5AK1euzNVXX51zzz23dtVux44d3vs0DAcOHMiLL75Ye7xt27Y8/fTTaW5uzsyZM+s42dhw3XXXZcOGDXnggQfS2NhYu6LX1NSUSZMm1Xm6glU5Js8880x18eLF1ebm5mpDQ0N19uzZ1S996UvVXbt21Xu0MeOuu+6qJjnqxrFbtmzZUc/hI488Uu/RivWd73ynOmvWrOqECROqH/rQh6qbN2+u90hjyiOPPHLUP3PLli2r92hjwlv9vXfXXXfVe7SiuQ8KAFAcbwAAAIojUACA4ggUAKA4AgUAKI5AAQCKI1AAgOIIFACgOAIFACiOQAEAiiNQAIDiCBQAoDgCBQAozv8C/4xSeNEIgJsAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(rn.numpy())\n",
    "plt.hist(ru.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fedca8a-ea20-4aae-8eef-dbb96f3fa365",
   "metadata": {},
   "source": [
    "## 3. Basic Operations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeeb08b0-d00b-4958-aaaf-0b84b06d02f0",
   "metadata": {},
   "source": [
    "You can perform basic operations on tensors in PyTorch, such as addition, subtraction, multiplication, and division. Here are some examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "43cc7a23-18c0-4fe9-ad5c-139c85c38251",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating two tensors\n",
    "x = torch.randn(10)\n",
    "y = torch.randn(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6eb96038-025b-430a-8e23-d48c204decdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Addition\n",
    "z = x + y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c08728af-5a0f-49b2-a93c-b2471980ca77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subtraction\n",
    "w = x - y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7f8a31ae-7850-440d-bf43-36fe3965bc7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multiplication\n",
    "u = x * y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "af995018-94b6-42b2-a911-6dda629f5573",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Division\n",
    "v = x / y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fc1c666-a1c2-4f45-8862-fc1e4f5c2c7c",
   "metadata": {},
   "source": [
    "## 4. Reshaping Tensors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa31183f-511d-4d80-8ca7-02b348b95875",
   "metadata": {},
   "source": [
    "You can reshape tensors in PyTorch using the torch.view() method.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b43507d8-6545-4ea0-ac44-0ae98da6cbe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a tensor\n",
    "x =  torch.randn(10,2)\n",
    "\n",
    "# Reshaping the tensor\n",
    "y = x.view(5, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "166ef420-a7cc-49c3-a04f-68a0bb062cbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.9627,  0.1425],\n",
       "        [-1.3232, -0.6696],\n",
       "        [ 1.1260,  0.1141],\n",
       "        [ 1.0192,  0.3475],\n",
       "        [-0.1465,  0.3084],\n",
       "        [ 2.1176,  0.2210],\n",
       "        [-1.7417,  1.4311],\n",
       "        [-1.6304, -1.5402],\n",
       "        [-0.6487, -0.2962],\n",
       "        [ 0.2292, -0.8319]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a311e5e8-c828-452f-8b60-298712ca039d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.9627,  0.1425, -1.3232, -0.6696],\n",
       "        [ 1.1260,  0.1141,  1.0192,  0.3475],\n",
       "        [-0.1465,  0.3084,  2.1176,  0.2210],\n",
       "        [-1.7417,  1.4311, -1.6304, -1.5402],\n",
       "        [-0.6487, -0.2962,  0.2292, -0.8319]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9018e71-e472-45c6-bdf3-995f21205eff",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 5. Broadcasting tensors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2148199-8f0c-486c-a291-67a04c2b491d",
   "metadata": {},
   "source": [
    "Broadcasting is the implicit expansion of tensor dimensions to perform element-wise operations between tensors of different shapes. The basic idea behind broadcasting is to make the dimensions of the tensors compatible by expanding or repeating them as necessary, until they have the same shape."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10347a04-5af0-48eb-b927-482baf82777f",
   "metadata": {},
   "source": [
    "Operations between tensors with different shapes is a common scenario in neural networks, e.g. a batch of images with different dimensions, and you want to perform element-wise operations on each image with a single weight tensor. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "6d8b0b1e-6f7b-46ac-b994-6cdbcc9fd390",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([-0.5184,  0.2513, -1.8798]).reshape(1,3)\n",
    "y = np.array([[-0.4436],\n",
    "        [-0.6684],\n",
    "        [ 0.2567]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "85e81e16-fdf6-42d3-bde8-51a05774c361",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1, 3), (3, 1))"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "85e38905-9d3c-4ee1-8477-6cf68a26bf64",
   "metadata": {},
   "outputs": [],
   "source": [
    "z = x+y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "94d62098-f515-4742-9761-fc8d0fb24949",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.962 , -0.1923, -2.3234],\n",
       "       [-1.1868, -0.4171, -2.5482],\n",
       "       [-0.2617,  0.508 , -1.6231]])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d56f1f05-677c-4235-8131-7e4491f2b40e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating two tensors\n",
    "x = torch.randn(1,3)\n",
    "y = torch.randn(3,1)\n",
    "\n",
    "# Broadcasting the tensors\n",
    "z = x + y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c1832417-575c-418b-994d-ef3cd5412008",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.4436],\n",
       "        [-0.6684],\n",
       "        [ 0.2567]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d3f0646-0b9a-48d0-ad20-3a384d42d528",
   "metadata": {},
   "source": [
    "## 6. Indexing and Slicing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe6539ac-0004-4a60-9e98-482634fdbe05",
   "metadata": {},
   "source": [
    "You can index and slice tensors in PyTorch to access specific elements as in numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "43839102-a5df-406f-b499-b99bed25f9c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(3,3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "cd76da0a-ceed-4733-91fa-a22470ed88c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1875, -0.1424, -0.0048],\n",
       "        [ 2.1631, -0.6570,  0.4103],\n",
       "        [-0.7218, -0.5961,  0.9048]])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "e49004bd-6a16-4ed8-9db9-0eee8e2a3df3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.4103)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Indexing a tensor\n",
    "y = x[1, 2]  \n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "28bb6819-afc1-4c19-aad1-06a85cd1df9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.1424, -0.6570, -0.5961])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z = x[:, 1] \n",
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "7943692f-1a1e-4268-86ed-6ea216d4ef85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-0.0048)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = x[0, -1] \n",
    "t"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64db0ef5-daf6-4fe1-8bed-f45b27c2c790",
   "metadata": {},
   "source": [
    "## 7. Moving Tensors to GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bf3bc30-409d-4a68-986a-267e14a9f767",
   "metadata": {},
   "source": [
    "If you have a CUDA-enabled GPU, you can move tensors to the GPU to speed up computations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "44446ad9-a973-47bb-8975-b2e843abe4f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking if the gpu is available\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "68311df8-ea5a-4ab9-b94b-a3a0424d7e74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a tensor\n",
    "x = torch.randn(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "583be6ff-1423-4524-b99a-311ea426b69b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.4668, -1.1362,  0.8251])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "49c1ad49-a3ab-4ef6-9a15-72adb20c9769",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Moving the tensor to GPU\n",
    "x = x.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "b1af64da-aa1d-4599-9de6-cdbf63cb7e28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.4668, -1.1362,  0.8251], device='cuda:0')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "31d320b5-4cba-4502-98eb-175bc2866507",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting the device to gpu fs available, cpu if not\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "a92b58db-707a-49ee-9b3b-3d65b1c13560",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = x.to(device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DLenv2",
   "language": "python",
   "name": "dlenv2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
